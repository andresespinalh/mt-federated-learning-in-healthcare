{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics.classification as M\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchinfo import summary\n",
    "from model_architectures import FNNEegSignals\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "from IPython import display\n",
    "from scipy.signal import savgol_filter\n",
    "display.set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to swap between CPU/GPU\n",
    "device = torch.device('cuda:0')\n",
    "# device = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder containing the pre-splitted folds\n",
    "# dir_folds = '../../../data/outputs/eeg-signals/data-prep/partitions/3-flclients-patient-dist-os'\n",
    "dir_folds = '../../../data/outputs/eeg-signals/data-prep/partitions/3-flclients'\n",
    "files_names = os.listdir(dir_folds)\n",
    "k_folds = int(len(files_names) / 2)\n",
    "\n",
    "folds = {}\n",
    "\n",
    "# Assign each fold (x, y sets) an entry in the dictionary\n",
    "for fold in range(1, k_folds + 1):\n",
    "    x_val = pd.read_csv(f'{dir_folds}/eeg_x_dev_flc{fold}.csv')\n",
    "    y_val = pd.read_csv(f'{dir_folds}/eeg_y_dev_flc{fold}.csv')\n",
    "    folds[fold] = {'x_val': x_val, 'y_val': y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnn = FNNEggSignals(4, 64)\n",
    "# summary(fnn, input_data=features, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training/Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vram_usage():\n",
    "    try:\n",
    "        cmd = ['nvidia-smi', '--query-gpu=memory.used', '--format=csv,noheader,nounits']\n",
    "        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        if result.returncode == 0:\n",
    "            vram_used = int(result.stdout.strip())\n",
    "            return vram_used\n",
    "        else:\n",
    "            print(\"Error:\", result.stderr, flush='True')\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e, flush='True')\n",
    "    return None\n",
    "\n",
    "def train(model, x_train, y_train, x_val, y_val, exp_conf, exp_name):\n",
    "    # Get the value to scale the weights based on class imbalance\n",
    "    n_pos = torch.tensor(y_train[y_train==1].shape[0]).float()\n",
    "    n_neg = torch.tensor(y_train[y_train==0].shape[0]).float()\n",
    "    pos_weight = n_neg / n_pos\n",
    "\n",
    "    # Loss Function\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    # loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = getattr(torch.optim, exp_conf['optimizer'])\n",
    "    optimizer = optimizer(model.parameters(), lr=exp_conf['learning_rate'])\n",
    "\n",
    "    # Metrics Accumulators\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_sensitivities = []\n",
    "    train_specificities = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_sensitivities = []\n",
    "    val_specificities = []\n",
    "\n",
    "    # Define evaluation metrics settings\n",
    "    accuracy_metric = M.BinaryAccuracy(threshold=exp_conf['decision_boundary']).to(device)\n",
    "    recall_metric = M.BinaryRecall(threshold=exp_conf['decision_boundary']).to(device)\n",
    "    specificity_metric = M.BinarySpecificity(threshold=exp_conf['decision_boundary']).to(device)\n",
    "\n",
    "    # For each training epoch\n",
    "    for epoch_i in range(exp_conf['n_epochs']):\n",
    "        ## Training\n",
    "        model.train()\n",
    "        \n",
    "        # Update on progress\n",
    "        print(f'Running {exp_name}, epoch {epoch_i} of {exp_conf[\"n_epochs\"]-1}')\n",
    "        display.clear_output(wait=True)\n",
    "        \n",
    "        # Forward Pass\n",
    "        y_hat = model(x_train)\n",
    "\n",
    "        # Compute the Loss\n",
    "        train_loss = loss_function(y_hat, y_train)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ## Compute epoch training metrics\n",
    "        y_pred = torch.sigmoid(y_hat)\n",
    "        train_accuracy = accuracy_metric(y_pred, y_train)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        train_sensitivity = recall_metric(y_pred, y_train)\n",
    "        train_sensitivities.append(train_sensitivity)\n",
    "        train_specificity = specificity_metric(y_pred, y_train)\n",
    "        train_specificities.append(train_specificity)\n",
    "\n",
    "        ## Compute epoch evaluation metrics\n",
    "        val_results = evaluate(model, x_val, y_val, exp_conf)\n",
    "        val_losses.append(val_results['loss'])\n",
    "        val_accuracies.append(val_results['accuracy'])\n",
    "        val_sensitivities.append(val_results['sensitivity'])\n",
    "        val_specificities.append(val_results['specificity'])\n",
    "\n",
    "        vram_used = get_vram_usage()\n",
    "        dict_memory = {\n",
    "            'epoch': [epoch_i]\n",
    "            , 'VRAM': [vram_used]\n",
    "        }\n",
    "\n",
    "        # print(dict_memory, flush=True\n",
    "        df_memory = pd.DataFrame.from_dict(dict_memory)\n",
    "        filename = f'{exp_conf[\"logs_path\"]}/fnn_memory_centralized.csv'\n",
    "        df_memory.to_csv(filename, index=False, mode='a', header=not os.path.exists(filename))\n",
    "\n",
    "    # Collect all objects in CPU\n",
    "    result = {\n",
    "        # Training\n",
    "        'train_losses': torch.as_tensor(train_losses).cpu()\n",
    "        , 'train_accuracies': torch.as_tensor(train_accuracies).cpu()\n",
    "        , 'train_sensitivities': torch.as_tensor(train_sensitivities).cpu()\n",
    "        , 'train_specificities': torch.as_tensor(train_specificities).cpu()\n",
    "        # Validation\n",
    "        , 'val_losses': torch.as_tensor(val_losses).cpu()\n",
    "        , 'val_accuracies': torch.as_tensor(val_accuracies).cpu()\n",
    "        , 'val_sensitivities': torch.as_tensor(val_sensitivities).cpu()\n",
    "        , 'val_specificities': torch.as_tensor(val_specificities).cpu()\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "def evaluate(model, x_val, y_val, exp_conf):\n",
    "    model.eval()\n",
    "    # Get the value to scale the weights based on class imbalance\n",
    "    n_pos = torch.tensor(y_val[y_val==1].shape[0]).float()\n",
    "    n_neg = torch.tensor(y_val[y_val==0].shape[0]).float()\n",
    "    pos_weight = n_neg / n_pos\n",
    "\n",
    "    # Loss Function\n",
    "    loss_function = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    # loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_hat = model(x_val)\n",
    "        loss = loss_function(y_hat, y_val)\n",
    "        y_pred = torch.sigmoid(y_hat)\n",
    "\n",
    "        # Define evaluation metrics settings\n",
    "        accuracy_metric = M.BinaryAccuracy(threshold=exp_conf['decision_boundary']).to(device)\n",
    "        recall_metric = M.BinaryRecall(threshold=exp_conf['decision_boundary']).to(device)\n",
    "        specificity_metric = M.BinarySpecificity(threshold=exp_conf['decision_boundary']).to(device)\n",
    "\n",
    "        # Compute metrics\n",
    "        accuracy = accuracy_metric(y_pred, y_val)\n",
    "        sensitivity = recall_metric(y_pred, y_val)\n",
    "        specificity = specificity_metric(y_pred, y_val)\n",
    "\n",
    "        results = {'loss': loss, 'accuracy': accuracy, 'sensitivity': sensitivity, 'specificity': specificity}\n",
    "\n",
    "    return results\n",
    "\n",
    "def compile_results(epoch_results, exp_conf, elapsed_time, filepath):\n",
    "    ## Training Results (Wide Format)\n",
    "    results_wide_df = pd.DataFrame.from_dict(epoch_results, orient='columns')\n",
    "    results_wide_df['epoch'] = [epoch for epoch in range(exp_conf['n_epochs'])]\n",
    "    results_wide_df['exp_name'] = exp_conf['experiment_name']\n",
    "\n",
    "    ## Training Results (Long Format)\n",
    "    results_long_df = pd.melt(frame=results_wide_df, id_vars=['epoch', 'exp_name'], value_vars=epoch_results.keys(), var_name='metric', value_name='value')\n",
    "    results_long_df = results_long_df.sort_values('epoch')\n",
    "\n",
    "    ## Training Summary \n",
    "    epoch_best_model = epoch_results['val_losses_mean'].argmin()\n",
    "    \n",
    "    summary_exp = {\n",
    "        'exp_name': [exp_conf['experiment_name']]\n",
    "        , 'exp_type': [exp_conf['experiment_type']]\n",
    "        , 'exp_resource': [exp_conf['resource']]\n",
    "        , 'exp_device': [exp_conf['device']]\n",
    "        , 'exp_k_folds': [exp_conf['k-folds']]\n",
    "        , 'exp_configuration': [json.dumps(exp_conf)]\n",
    "        , 'elapsed_time': [elapsed_time]\n",
    "        , 'epoch_best_model': epoch_best_model\n",
    "    }\n",
    "\n",
    "    # Get the aggregated metrics for the epoch with the best model performance\n",
    "    for metric_name in epoch_results.keys():\n",
    "        if('mean' in metric_name):\n",
    "            metric_value = epoch_results[metric_name][epoch_best_model]\n",
    "            summary_exp[metric_name] = [metric_value]\n",
    "\n",
    "    exp_summary_df = pd.DataFrame.from_dict(summary_exp, orient='columns')\n",
    "\n",
    "    # Persist experiments to disk (If path is provided)\n",
    "    if(filepath!=None):\n",
    "        filename_train_wide = f'{filepath}/results_train_wide.csv'\n",
    "        results_wide_df.to_csv(filename_train_wide, index=False, mode='a', header=not os.path.exists(filename_train_wide))\n",
    "        filename_train_long = f'{filepath}/results_train_long.csv'\n",
    "        results_long_df.to_csv(filename_train_long, index=False, mode='a', header=not os.path.exists(filename_train_long))\n",
    "        filename_summary = f'{filepath}/exp_summary_train.csv'\n",
    "        exp_summary_df.to_csv(filename_summary, index=False, mode='a', header=not os.path.exists(filename_summary))\n",
    "    \n",
    "    return {\n",
    "        'results': {'wide': results_wide_df, 'long': results_long_df}\n",
    "        , 'summary_exp': exp_summary_df\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Configuration\n",
    "exp_conf = {\n",
    "    # Experiment Metadata\n",
    "    'experiment_name': '2L_64U_Adam_1e-2_E3000_BSS_WeightedLoss'\n",
    "    , 'experiment_type': 'Centralized'\n",
    "    , 'resource': 'Cloud'\n",
    "    , 'device': device.type\n",
    "    , 'k-folds': k_folds\n",
    "    # Architecture Parameters\n",
    "    , 'n_epochs': 3000\n",
    "    , 'n_layers': 2\n",
    "    , 'n_units': 64\n",
    "    , 'learning_rate': 1e-2\n",
    "    , 'decision_boundary': 0.5\n",
    "    , 'perc_dropout': 0.0\n",
    "    , 'optimizer': 'Adam'\n",
    "    , 'loss_function': 'BCEWithLogitsLoss'\n",
    "} "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulators\n",
    "fold_results = {\n",
    "    'train_losses': [], 'train_accuracies': [], 'train_sensitivities': [], 'train_specificities': []\n",
    "    , 'val_losses': [], 'val_accuracies': [], 'val_sensitivities': [], 'val_specificities': []\n",
    "}\n",
    "\n",
    "elapsed_times = []\n",
    "\n",
    "# Per K-Fold\n",
    "for fold in folds.keys():\n",
    "    # Select the current fold for validation \n",
    "    x_val = folds[fold]['x_val']\n",
    "    y_val = folds[fold]['y_val']\n",
    "\n",
    "    # Union the rest of the folds for training\n",
    "    train_folds = {key: value for key, value in folds.items() if key != fold}\n",
    "    x_train = pd.DataFrame()\n",
    "    y_train = pd.DataFrame()\n",
    "\n",
    "    for train_fold in train_folds:\n",
    "        x_train = pd.concat([x_train, train_folds[train_fold]['x_val']])\n",
    "        y_train = pd.concat([y_train, train_folds[train_fold]['y_val']])\n",
    "\n",
    "    # Z-Score Normalization\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_val = scaler.fit_transform(x_val)\n",
    "\n",
    "    # Load the current fold sets into PyTorch Tensors\n",
    "    x_train = torch.tensor(x_train, device=device).float()\n",
    "    y_train = torch.tensor(y_train.values, device=device).float()\n",
    "    x_val = torch.tensor(x_val, device=device).float()\n",
    "    y_val = torch.tensor(y_val.values, device=device).float()\n",
    "\n",
    "    # Create a fresh instance of the model\n",
    "    fnn = FNNEegSignals(exp_conf['n_layers'], exp_conf['n_units'], exp_conf['perc_dropout'])\n",
    "    fnn.to(device)\n",
    "\n",
    "    fold_start_time = time.time()\n",
    "    # Train this fold\n",
    "    result = train(fnn, x_train, y_train, x_val, y_val, exp_conf, f'{exp_conf[\"experiment_name\"]} Fold {fold}')\n",
    "    fold_end_time = time.time()\n",
    "    fold_elapsed_time = fold_end_time - fold_start_time\n",
    "    elapsed_times.append(fold_elapsed_time)\n",
    "\n",
    "    # Accumulate metrics\n",
    "    for metric in result.keys():    \n",
    "        fold_results[metric].append(result[metric])\n",
    "\n",
    "    # Free GPU memory after each run\n",
    "    del fnn, x_train, y_train, x_val, y_val\n",
    "    torch.cuda.empty_cache() \n",
    "    gc.collect()\n",
    "\n",
    "## Aggregate Fold Measures\n",
    "agg_fold_results = {}\n",
    "\n",
    "for metric_name in fold_results.keys():\n",
    "    metric_matrix = np.array([]).reshape(0, exp_conf['n_epochs'])\n",
    "    \n",
    "    for fold, metric in enumerate(fold_results[metric_name]):\n",
    "        metric = metric.reshape(1, exp_conf['n_epochs'])\n",
    "        metric_matrix = np.vstack([metric_matrix, metric])\n",
    "    \n",
    "    metric_mean = metric_matrix.mean(axis=0)\n",
    "    metric_sd = metric_matrix.std(axis=0)\n",
    "    agg_fold_results[f'{metric_name}_mean'] = metric_mean\n",
    "    agg_fold_results[f'{metric_name}_std'] = metric_sd\n",
    "\n",
    "epoch_results = {key: agg_fold_results[key] for key in agg_fold_results.keys() if 'mean' in key}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = np.array(elapsed_times).sum()\n",
    "filepath = '../../../data/logs/experiments/eegsignals_ffn'\n",
    "# filepath = None # Disable Persistence\n",
    "\n",
    "# Create path if it doesn't exist\n",
    "if((filepath!=None) & (~os.path.exists(filepath))):\n",
    "    os.makedirs(filepath)\n",
    "    \n",
    "comp_train_results = compile_results(agg_fold_results, exp_conf, elapsed_time, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs, axs = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for fold in range(0, k_folds):\n",
    "    axs[fold].set_title(f'Fold {fold+1} Loss')\n",
    "    axs[fold].set_xlabel('Epoch')\n",
    "    axs[fold].set_ylabel('Loss')\n",
    "    axs[fold].plot(fold_results['train_losses'][fold], label=f'Train', color='C0')\n",
    "    axs[fold].plot(fold_results['val_losses'][fold], label=f'Val', color='C1')\n",
    "    axs[fold].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_train_results['summary_exp']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-dudlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
