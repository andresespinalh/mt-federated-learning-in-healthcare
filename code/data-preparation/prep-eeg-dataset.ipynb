{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import os, shutil\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "import queue\n",
    "from math import floor\n",
    "from shutil import rmtree\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read all the .npy files, build consolidated CSV files (Features/Labels) and export it to disk \n",
    "def consolidate_data(path_files, path_output):\n",
    "    filenames = ['{0}\\\\{1}'.format(path_files, file) for file in os.listdir(path_files)]\n",
    "    feature_files = [file for file in filenames if 'data_pattern' in file]\n",
    "    label_files = [file for file in filenames if 'label_pattern' in file]\n",
    "\n",
    "    # Labels\n",
    "    labels_map = []\n",
    "\n",
    "    for file in label_files[0:10]:\n",
    "        curr_label = cp.load(file)\n",
    "        # File, Label, Patient\n",
    "        row = [file.split('\\\\')[-1], curr_label[0].item(), curr_label[1].item()]\n",
    "        labels_map.append(row)\n",
    "\n",
    "    labels_map_df = pd.DataFrame(labels_map, columns=['File', 'Label', 'Patient'])\n",
    "    labels_map_df.to_csv(f'{path_output}/eeg_labels.csv', index=False)\n",
    "\n",
    "    # Features\n",
    "    features_map = []\n",
    "\n",
    "    for file in feature_files[0:10]:\n",
    "        curr_file = cp.load(file)\n",
    "        row = curr_file[0].tolist()\n",
    "        row.insert(0, file.split('\\\\')[-1])\n",
    "        features_map.append(row)\n",
    "\n",
    "    feature_names = [f'F{feature_number + 1}' for feature_number in range(53)]\n",
    "    feature_names.insert(0, 'File')\n",
    "    features_map_df = pd.DataFrame(features_map, columns=feature_names)\n",
    "    features_map_df.to_csv(f'{path_output}/eeg_features.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects a folder with the extracted .npy files\n",
    "# ! This is an expensive operation, proceed with caution\n",
    "path_files = \"..\\..\\data\\outputs\\eeg-signals\\data-prep\\non DL models Gcloud\"\n",
    "path_output = \"..\\..\\data\\outputs\\eeg-signals\\data-prep\"\n",
    "consolidate_data(path_files, path_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partitioning (Stratified Sampling / Cross-Patient Distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Centralized Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"../../data/outputs/eeg-signals/data-prep/eeg_features.csv\").drop('File', axis=1)\n",
    "labels = pd.read_csv(\"../../data/outputs/eeg-signals/data-prep/eeg_labels.csv\")['Label']\n",
    "\n",
    "# Flip the labels (Preictal: 1, Interictal: 0)\n",
    "labels = pd.Series(np.where(labels==0, 1, 0)).to_frame('Label')\n",
    "\n",
    "# Split the data for the centralized approach\n",
    "# First separate the train set from a 30% holdout-set\n",
    "x_train, x_holdout, y_train, y_holdout = train_test_split(features, labels, test_size=0.30, shuffle=True, random_state=64, stratify=labels)\n",
    "# Then split the holdout-set in half to get the evaluation and test sets\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_holdout, y_holdout, test_size=0.5, shuffle=True, random_state=64, stratify=y_holdout)\n",
    "\n",
    "output_dir = '../../data/outputs/eeg-signals/data-prep/partitions/centralized-stratified'\n",
    "\n",
    "# Clean the directory first\n",
    "if os.path.exists(output_dir): \n",
    "    shutil.rmtree(output_dir)\n",
    "    \n",
    "os.makedirs(output_dir) \n",
    "\n",
    "# Export Features\n",
    "x_train.to_csv(f'{output_dir}/eeg_x_train.csv', header=True, index=False)\n",
    "x_val.to_csv(f'{output_dir}/eeg_x_val.csv', header=True, index=False)\n",
    "x_test.to_csv(f'{output_dir}/eeg_x_test.csv', header=True, index=False)\n",
    "\n",
    "# Export Labels\n",
    "y_train.to_csv(f'{output_dir}/eeg_y_train.csv', header=True, index=False)\n",
    "y_val.to_csv(f'{output_dir}/eeg_y_val.csv', header=True, index=False)\n",
    "y_test.to_csv(f'{output_dir}/eeg_y_test.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Federated Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev = x_train\n",
    "y_dev = y_train\n",
    "\n",
    "# How many powers of 2 to have as configurations\n",
    "n_fl_configs = 4\n",
    "fl_configs = [2**config for config in range(1, n_fl_configs + 1, 1)]\n",
    "fl_partitions = {}\n",
    "\n",
    "# Get a mapping of the patients in each federated client, per federated configuration\n",
    "for levels, fl_config in enumerate(fl_configs):\n",
    "    levels += 1\n",
    "    conf_partitions = []\n",
    "\n",
    "    # Start the queue with the whole dataset\n",
    "    partition_queue = queue.Queue()\n",
    "    temp_queue = queue.Queue()\n",
    "    partition_queue.put({'x_dev': x_dev, 'y_dev': y_dev})\n",
    "\n",
    "    for level in range(1, levels + 1, 1):\n",
    "        # Grab from the partition queue, split in 2 stratified partitions and append to the temporal queue, until empty\n",
    "        while not partition_queue.empty():\n",
    "            next_element = partition_queue.get()\n",
    "            x_dev_partition = next_element['x_dev']\n",
    "            y_dev_partition = next_element['y_dev']\n",
    "\n",
    "            # Partition the dataset in the queue into 2 stratified dataframes\n",
    "            x_dev_1, x_dev_2, y_dev_1, y_dev_2  = train_test_split(x_dev_partition, y_dev_partition, test_size=0.5, shuffle=True, random_state=64, stratify=y_dev_partition)\n",
    "        \n",
    "            # Store each partition in the queue for future splitting \n",
    "            temp_queue.put({'x_dev': x_dev_1, 'y_dev': y_dev_1})\n",
    "            temp_queue.put({'x_dev': x_dev_2, 'y_dev': y_dev_2})\n",
    "        \n",
    "        fl_client = 1\n",
    "        fl_config = temp_queue.qsize()\n",
    "        fl_partitions[fl_config] = []\n",
    "\n",
    "        # Get the next element in the temp queue and add it to the partition queue for future partitioning\n",
    "        while not temp_queue.empty():\n",
    "            next_element = temp_queue.get()\n",
    "            partition_queue.put(next_element)\n",
    "            fl_partitions[fl_config].append(next_element)\n",
    "            fl_client += 1\n",
    "\n",
    "partitions = list(partition_queue.queue)\n",
    "\n",
    "# Save all partitions to disk\n",
    "for fl_config in fl_partitions.keys():\n",
    "    output_dir = f'../../data/outputs/eeg-signals/data-prep/partitions/fl-stratified/{fl_config}-flclients'\n",
    "\n",
    "    # Clean the directory first\n",
    "    if os.path.exists(output_dir): \n",
    "        shutil.rmtree(output_dir)\n",
    "        \n",
    "    os.makedirs(output_dir) \n",
    "\n",
    "    for fl_client, partition_df in enumerate(fl_partitions[fl_config]):\n",
    "        fl_client += 1\n",
    "        partition_df['x_dev'].to_csv(f'{output_dir}/eeg_x_train_flc{fl_client}.csv', header=True, index=False)\n",
    "        partition_df['y_dev'].to_csv(f'{output_dir}/eeg_y_train_flc{fl_client}.csv', header=True, index=False)\n",
    "        partition_df['y_dev']\n",
    "\n",
    "## Export partitions stats for federated distribution analysis\n",
    "stats = []\n",
    "\n",
    "for key in fl_partitions.keys():\n",
    "    fl_client = 0\n",
    "\n",
    "    for client in range(0, len(fl_partitions[key])):\n",
    "        fl_client += 1\n",
    "        labels_df = fl_partitions[key][client][\"y_dev\"]\n",
    "        props = round((labels_df['Label'].value_counts() / labels_df.shape[0])*100, 2)\n",
    "        prop_examples = round((labels_df.shape[0] / y_train.shape[0])*100, 2)\n",
    "    \n",
    "        summary = {'fl_config': key, 'fl_client': fl_client, 'prop_neg': props[0], 'prop_pos': props[1], 'prop_examples': prop_examples}\n",
    "        stats.append(summary)\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "\n",
    "output_dir = f'../../data/outputs/eda'\n",
    "\n",
    "# Clean the directory first\n",
    "if os.path.exists(output_dir): \n",
    "    shutil.rmtree(output_dir)\n",
    "        \n",
    "os.makedirs(output_dir) \n",
    "\n",
    "stats_df.to_csv(f'{output_dir}/stats_eeg_fl_stratified.csv', header=True, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Partitioning (Patient-Aware Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Centralized Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "features_df = pd.read_csv(\"../../data/outputs/eeg-signals/data-prep/eeg_features.csv\")\n",
    "labels_df = pd.read_csv(\"../../data/outputs/eeg-signals/data-prep/eeg_labels.csv\")\n",
    "labels_df['Label'] = pd.Series(np.where(labels_df['Label']==0, 1, 0))\n",
    "\n",
    "# Get the amount of examples per patient\n",
    "df_patients = labels_df.groupby('Patient')['File'].count().rename('Examples').reset_index()\n",
    "df_patients['Percentage'] = round((df_patients['Examples']/labels_df.shape[0])*100, 3)\n",
    "df_patients = df_patients.sort_values('Percentage', ascending=False)\n",
    "\n",
    "# Select patients that will be included in the test set (The number of patients was calibrated to account around 15% of the data)\n",
    "holdout_patients = df_patients.sample(frac=0.25, random_state=64)['Patient'].to_list()\n",
    "train_patients = [patient for patient in df_patients['Patient'].to_list() if patient not in holdout_patients]\n",
    "test_patients = holdout_patients[:4]\n",
    "val_patients = holdout_patients[4:]\n",
    "\n",
    "# Check which examples go in each bucket\n",
    "is_train_patient = labels_df['Patient'].isin(train_patients)\n",
    "is_val_patient = labels_df['Patient'].isin(test_patients)\n",
    "is_test_patient = labels_df['Patient'].isin(val_patients)\n",
    "\n",
    "# Sanity Checks\n",
    "holdout_patients_cnt = is_val_patient.value_counts()[True] + is_test_patient.value_counts()[True]\n",
    "train_patients_cnt = is_train_patient.value_counts()[True]\n",
    "val_patients_cnt = is_val_patient.value_counts()[True]\n",
    "test_patients_cnt = is_test_patient.value_counts()[True]\n",
    "total_patients_cnt = labels_df.shape[0]\n",
    "\n",
    "print(f'% of examples in training set: {(total_patients_cnt-holdout_patients_cnt)/total_patients_cnt: .2f}')\n",
    "print(f'% of examples in holdout set: {holdout_patients_cnt/total_patients_cnt: .2f}')\n",
    "print(f'- % of examples in validation set: {val_patients_cnt/total_patients_cnt: .2f}')\n",
    "print(f'- % of examples in testing set: {test_patients_cnt/total_patients_cnt: .2f}')\n",
    "\n",
    "# Split into train, val and test sets\n",
    "x_train = features_df[is_train_patient].drop('File', axis=1)\n",
    "y_train = labels_df[is_train_patient]['Label'].to_frame('Label')\n",
    "x_val = features_df[is_val_patient].drop('File', axis=1)\n",
    "y_val = labels_df[is_val_patient]['Label'].to_frame('Label')\n",
    "x_test = features_df[is_test_patient].drop('File', axis=1)\n",
    "y_test = labels_df[is_test_patient]['Label'].to_frame('Label')\n",
    "\n",
    "# Write results to disk\n",
    "output_dir = '../../data/outputs/eeg-signals/data-prep/partitions/centralized-patient-aware'\n",
    "\n",
    "# Clean the directory first\n",
    "if os.path.exists(output_dir): \n",
    "    shutil.rmtree(output_dir)\n",
    "    \n",
    "os.makedirs(output_dir) \n",
    "\n",
    "# Export Features\n",
    "x_train.to_csv(f'{output_dir}/eeg_x_train.csv', header=True, index=False)\n",
    "x_val.to_csv(f'{output_dir}/eeg_x_val.csv', header=True, index=False)\n",
    "x_test.to_csv(f'{output_dir}/eeg_x_test.csv', header=True, index=False)\n",
    "\n",
    "# Export Labels\n",
    "y_train.to_csv(f'{output_dir}/eeg_y_train.csv', header=True, index=False)\n",
    "y_val.to_csv(f'{output_dir}/eeg_y_val.csv', header=True, index=False)\n",
    "y_test.to_csv(f'{output_dir}/eeg_y_test.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Federated Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a mapping of the patients in each federated client, per federated configuration\n",
    "fl_map_dict = {}\n",
    "\n",
    "queue_patients = queue.Queue()\n",
    "\n",
    "for client_config in [2, 4, 8, 16]:\n",
    "    for patient in train_patients:\n",
    "        queue_patients.put(patient)\n",
    "\n",
    "    # Initialize the client dictionary with lists\n",
    "    client_patient_dict = {}\n",
    "\n",
    "    for client in range(1, client_config + 1):\n",
    "        client_patient_dict[client] = []\n",
    "    \n",
    "    # Until the queue is empty and all the clients have been traversed\n",
    "    partition = 1\n",
    "    while not queue_patients.empty():\n",
    "        curr_patient = queue_patients.get()\n",
    "        client_patient_dict[partition].append(curr_patient)\n",
    "\n",
    "        if(partition==client_config):\n",
    "            partition = 1\n",
    "        else:\n",
    "            partition += 1\n",
    "\n",
    "    fl_map_dict[client_config] = client_patient_dict\n",
    "\n",
    "# Save all partitions to disk\n",
    "for fl_config in fl_map_dict.keys():\n",
    "    output_dir = f'../../data/outputs/eeg-signals/data-prep/partitions/fl-patient-aware/{fl_config}-flclients'\n",
    "\n",
    "    # Clean the directory first\n",
    "    if os.path.exists(output_dir): \n",
    "        shutil.rmtree(output_dir)\n",
    "        \n",
    "    os.makedirs(output_dir) \n",
    "\n",
    "    for fl_client in fl_map_dict[fl_config].keys():\n",
    "        partition_patients = fl_map_dict[fl_config][fl_client]\n",
    "        include_patients = labels_df['Patient'].isin(partition_patients)\n",
    "    \n",
    "        x_dev_partition_df = features_df[include_patients].drop('File', axis=1)\n",
    "        y_dev_partition_df = labels_df[include_patients]['Label']\n",
    "\n",
    "        x_dev_partition_df.to_csv(f'{output_dir}/eeg_x_train_flc{fl_client}.csv', header=True, index=False)\n",
    "        y_dev_partition_df.to_csv(f'{output_dir}/eeg_y_train_flc{fl_client}.csv', header=True, index=False)\n",
    "\n",
    "## Export partitions stats for federated distribution analysis\n",
    "stats = []\n",
    "\n",
    "# For each fl config\n",
    "for fl_config in fl_map_dict.keys():\n",
    "    # tot_matches = 0\n",
    "    for fl_client in fl_map_dict[fl_config].keys():\n",
    "        partition_patients = fl_map_dict[fl_config][fl_client]\n",
    "        include_patients = labels_df['Patient'].isin(partition_patients)\n",
    "\n",
    "        y_dev_partition_df = labels_df[include_patients]\n",
    "        props = round((y_dev_partition_df['Label'].value_counts() / y_dev_partition_df.shape[0])*100, 2)\n",
    "        prop_examples = round((y_dev_partition_df.shape[0] / y_train.shape[0])*100, 2)\n",
    "    \n",
    "        summary = {'fl_config': fl_config, 'fl_client': fl_client, 'prop_neg': props[0], 'prop_pos': props[1], 'prop_examples': prop_examples}\n",
    "        stats.append(summary)\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "output_dir = f'../../data/outputs/eda'\n",
    "\n",
    "stats_df = pd.melt(stats_df, id_vars=['fl_config', 'fl_client'], value_name='value', value_vars=['prop_neg', 'prop_pos'])\n",
    "stats_df.to_csv(f'{output_dir}/stats_eeg_fl_patient-aware.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-dudlcourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
